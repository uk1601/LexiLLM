# LexiLLM: Your LLM Expert Assistant

LexiLLM is a specialized chatbot designed to assist with understanding and implementing Large Language Models. It provides expert guidance on LLM fundamentals, implementation strategies, model comparisons, and the latest trends in the field.

![LexiLLM Logo](assets/lexillm_logo.jpeg)

## Features

- ğŸ§  **LLM Fundamentals**: Explanations of transformer architecture, embeddings, attention mechanisms, and core concepts
- âš™ï¸ **Implementation Guidance**: Advice on fine-tuning, RAG, reducing hallucinations, and deployment
- âš–ï¸ **Model Comparisons**: Objective analysis of different LLM models like GPT-4, Claude, and Llama
- ğŸ“° **News & Trends**: Updates on the latest research, applications, and developments
- ğŸ‘¤ **Personalized Responses**: Information collection to tailor responses to your background and needs
- ğŸ”„ **Streaming Responses**: Real-time, token-by-token response generation
- ğŸ’¾ **User Profile Management**: Persistent user profiles across sessions

## Installation

### Prerequisites
- Python 3.10+
- OpenAI API key

### Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/lexillm.git
   cd lexillm
   ```

2. Create and activate a virtual environment:
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```

4. Create a `.env` file with your OpenAI API key:
   ```
   OPENAI_API_KEY=your_api_key_here
   ```

## Usage

### Command Line Interface

Run the CLI version:

```bash
./run.sh
```

Or with streaming enabled:

```bash
USE_STREAMING=true ./run.sh
```

### Streamlit Web Interface

Run the enhanced Streamlit UI:

```bash
./run_enhanced_ui.sh
```

### Example Interactions

```
LexiLLM: Welcome to LexiLLM! I'm your specialized assistant for Large Language Models. How can I help you today?

You: How do transformer models work?

LexiLLM: [Detailed explanation about transformer architecture...]
```

## Project Structure

```
LexiLLM/
â”œâ”€â”€ assets/               # Images and static files
â”œâ”€â”€ presentation/         # Project presentation materials
â”œâ”€â”€ src/                  # Source code
â”‚   â”œâ”€â”€ lexillm/          # Core LexiLLM package
â”‚   â”‚   â”œâ”€â”€ core/         # Core implementation
â”‚   â”‚   â”œâ”€â”€ modules/      # Functional modules
â”‚   â”‚   â””â”€â”€ ...           # Other components
â”‚   â”œâ”€â”€ ui/               # UI components
â”‚   â”œâ”€â”€ main.py           # CLI entry point
â”‚   â””â”€â”€ ui_streamlit_enhanced.py  # Web UI entry point
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ user_profiles/        # Saved user profiles
â”œâ”€â”€ .env                  # Environment variables
â”œâ”€â”€ requirements.txt      # Dependencies
â””â”€â”€ run.sh, run_enhanced_ui.sh, run_tests.sh  # Helper scripts
```

## Technologies Used

- **LangChain**: For LLM orchestration and chaining
- **OpenAI API**: For GPT model access
- **Streamlit**: For web interface
- **Pydantic**: For data validation
- **Python Dataclasses**: For structured data representation
- **Dotenv**: For environment variable management

## Testing

Run the test suite:

```bash
./run_tests.sh
```

## Future Improvements

- Expanding the knowledge base with more specialized LLM topics
- Adding visualization tools for LLM concepts
- Supporting more LLM providers beyond OpenAI
- Implementing a memory system for longer conversations
- Adding export functionality for conversation summaries

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Contact

Uday Kiran Dasari - uday.kiran.dasari@example.com

Northeastern University - Prompt Engineering - Spring 2025
